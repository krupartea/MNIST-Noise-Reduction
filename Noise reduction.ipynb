{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from ignite.metrics import Accuracy, Precision, Recall\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_1 = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "MNIST_2 = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noisy(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, phase=None):\n",
    "\n",
    "        if phase == 'train':\n",
    "            start = 0\n",
    "            end = int(len(dataset)*.75)\n",
    "        elif phase == 'val':\n",
    "            start = int(len(dataset)*.75)\n",
    "            end = len(dataset)\n",
    "        else:\n",
    "            start = 0\n",
    "            end = len(dataset)\n",
    "\n",
    "        self.dataset = dataset.data[start:end] / 255\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        data = (self.dataset[idx] + torch.rand(28, 28) * 0.33 ).unsqueeze(0)\n",
    "        target = self.dataset[idx].unsqueeze(0)\n",
    "            \n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISY_train_dataset = Noisy(MNIST_1, 'train')\n",
    "NOISY_val_dataset = Noisy(MNIST_1, 'val')\n",
    "NOISY_test_dataset = Noisy(MNIST_2, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].imshow(NOISY_train_dataset[0][0].squeeze(), cmap='gray')\n",
    "axs[1].imshow(NOISY_train_dataset[0][1].squeeze(), cmap='gray')\n",
    "\n",
    "axs[0].title.set_text('Data')\n",
    "axs[1].title.set_text('Target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = nn.Sequential(\n",
    "    # encode\n",
    "    nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # decode\n",
    "    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "denoiser.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, learning_rate, num_epochs, train_dataset, val_dataset,\n",
    "               criterion, optimizer, scheduler):\n",
    "    \n",
    "    criterion = criterion()\n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    scheduler = scheduler(optimizer)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    total_progress = tqdm(total=num_epochs, desc='Total progress')\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # do not compute accuracy for regression problems\n",
    "    classification = criterion == torch.nn.CrossEntropyLoss()\n",
    "    if classification:\n",
    "        epoch_accuracies = []\n",
    "        accuracy = Accuracy()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_progress = tqdm(total=len(train_loader), desc=f'Training epoch #{epoch}...', leave=False)\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_progress.update()\n",
    "        epoch_progress.close()\n",
    "\n",
    "        model.eval()\n",
    "        val_progress = tqdm(total=len(val_loader), desc=f'Validating epoch #{epoch}...', leave=False)\n",
    "        val_losses = []\n",
    "        \n",
    "        if classification:\n",
    "            accuracy.reset()\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_losses.append(loss.item())\n",
    "            val_progress.update()\n",
    "            if classification:\n",
    "                accuracy.update((output, target))\n",
    "        val_progress.close()\n",
    "\n",
    "        mean_val_loss = np.mean(val_losses)\n",
    "        epoch_losses.append(mean_val_loss)\n",
    "        if classification:\n",
    "            current_accuracy = accuracy.compute()\n",
    "            epoch_accuracies.append(current_accuracy)\n",
    "            if current_accuracy == max(epoch_accuracies):\n",
    "                torch.save(model, 'classifier_best_accuracy.pt')\n",
    "        else:\n",
    "            if mean_val_loss == min(epoch_losses):\n",
    "                torch.save(model, 'denoiser_least_loss.pt')            \n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(mean_val_loss)\n",
    "\n",
    "        print(f\"Val loss #{epoch}: {np.mean(val_losses)}\")\n",
    "        if classification:\n",
    "            print(f\"Val accuracy #{epoch}: {current_accuracy}\")\n",
    "\n",
    "        total_progress.update()\n",
    "\n",
    "    total_progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b99435fbf464ec18f6ba83b78679c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total progress:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch #0...:   0%|          | 0/2813 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating epoch #0...:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss #0: 0.11087271707779817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23664138ab96437e8031e9c52b400b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch #1...:   0%|          | 0/2813 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8eb04dc0cb02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_model(model=denoiser,\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOISY_train_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c56233dd77dc>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, batch_size, learning_rate, num_epochs, train_dataset, val_dataset, criterion, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mepoch_progress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'Training epoch #{epoch}...'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model=denoiser,\n",
    "            batch_size=16,\n",
    "            learning_rate=0.01,\n",
    "            num_epochs=30,\n",
    "            train_dataset=NOISY_train_dataset,\n",
    "            val_dataset=NOISY_val_dataset,\n",
    "            criterion=torch.nn.MSELoss,\n",
    "            optimizer=optim.SGD,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "denoiser.eval()\n",
    "output = denoiser(NOISY_test_dataset[0][0].unsqueeze(0).to(device))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "axs[0].imshow(NOISY_test_dataset[0][0].squeeze(), cmap='gray')\n",
    "axs[1].imshow(output.cpu().detach().numpy().squeeze(), cmap='gray')\n",
    "axs[2].imshow(NOISY_test_dataset[0][1].squeeze(), cmap='gray')\n",
    "\n",
    "axs[0].title.set_text('Data')\n",
    "axs[1].title.set_text('Denoised')\n",
    "axs[2].title.set_text('Target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training a classifier (for the denoiser  evaluation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, phase=None, augment=False, normalize=False):\n",
    "        \n",
    "        if augment:\n",
    "            self.transform = A.Compose([\n",
    "                A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, p=1.0)\n",
    "            ])      \n",
    "        \n",
    "        self.augment = augment\n",
    "        self.normalize = normalize\n",
    "\n",
    "        if phase == 'train':\n",
    "            start = 0\n",
    "            end = int(len(dataset)*.75)\n",
    "        elif phase == 'val':\n",
    "            start = int(len(dataset)*.75)\n",
    "            end = len(dataset)\n",
    "        else:\n",
    "            start = 0\n",
    "            end = len(dataset)\n",
    "\n",
    "        self.data = dataset.data[start:end] / 255\n",
    "        self.targets = dataset.targets[start:end]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        data = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        if self.augment:\n",
    "            data = torch.tensor(self.transform(image=data.numpy())['image'])\n",
    "        \n",
    "        if self.normalize:\n",
    "            data = (data - data.mean()) / data.std()\n",
    "            \n",
    "        return data.unsqueeze(0), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train_dataset = MNIST(MNIST_1, 'train', True, True)\n",
    "MNIST_val_dataset = MNIST(MNIST_1, 'val', True, True)\n",
    "MNIST_test_dataset = MNIST(MNIST_2, 'test', False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(7*7*64, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = nn.Sequential(\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(28*28, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(64),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(64, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(64),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(64, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(64),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(64, 10)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, learning_rate, num_epochs, train_dataset, val_dataset,\n",
    "               criterion, optimizer, cheduler):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    total_progress = tqdm(total=num_epochs, desc='Total progress')\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # do not compute accuracy for regression problems\n",
    "    classification = criterion == torch.nn.CrossEntropyLoss()\n",
    "    if classification:\n",
    "        epoch_accuracies = []\n",
    "        accuracy = Accuracy()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_progress = tqdm(total=len(train_loader), desc=f'Training epoch #{epoch}...', leave=False)\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_progress.update()\n",
    "        epoch_progress.close()\n",
    "\n",
    "        model.eval()\n",
    "        val_progress = tqdm(total=len(val_loader), desc=f'Validating epoch #{epoch}...', leave=False)\n",
    "        val_losses = []\n",
    "        \n",
    "        if classification:\n",
    "            accuracy.reset()\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_losses.append(loss.item())\n",
    "            val_progress.update()\n",
    "            if classification:\n",
    "                accuracy.update((output, target))\n",
    "        val_progress.close()\n",
    "\n",
    "        mean_val_loss = np.mean(val_losses)\n",
    "        epoch_losses.append(mean_val_loss)\n",
    "        if classification:\n",
    "            current_accuracy = accuracy.compute()\n",
    "            epoch_accuracies.append(current_accuracy)\n",
    "            if current_accuracy == max(epoch_accuracies):\n",
    "                torch.save(model, 'classifier_best_accuracy.pt')\n",
    "        else:\n",
    "            if mean_val_loss == min(epoch_losses):\n",
    "                torch.save(model, 'denoiser_least_loss.pt')            \n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(mean_val_loss)\n",
    "\n",
    "        print(f\"Val loss #{epoch}: {np.mean(val_losses)}\")\n",
    "        if classification:\n",
    "            print(f\"Val accuracy #{epoch}: {current_accuracy}\")\n",
    "\n",
    "        total_progress.update()\n",
    "\n",
    "    total_progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "train_classifier(model=classifier,\n",
    "                 batch_size=256,\n",
    "                 learning_rate=0.1,\n",
    "                 num_epochs=30,\n",
    "                 train_dataset=MNIST_train_dataset,\n",
    "                 val_dataset=MNIST_val_dataset\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "best_denoiser = torch.load('denoiser_least_loss.pt')\n",
    "best_classifier = torch.load('classifier_best_accuracy.pt')\n",
    "\n",
    "best_denoiser.to(device).eval()\n",
    "best_classifier.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test_loader = torch.utils.data.DataLoader(MNIST_test_dataset, batch_size=256, shuffle=False)\n",
    "accuracy = Accuracy()\n",
    "precision = Precision()\n",
    "recall = Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(classifier, data_loader, accuracy, precision, recall, add_noise=False, denoiser=None):\n",
    "    \n",
    "    accuracy.reset()\n",
    "    precision.reset()\n",
    "    recall.reset()\n",
    "    \n",
    "    classifier.eval()\n",
    "    if denoiser:\n",
    "        denoiser.eval()\n",
    "        \n",
    "    for data, target in data_loader:\n",
    "        \n",
    "            data = data.to(device)\n",
    "            \n",
    "            if add_noise:\n",
    "                noise = torch.rand(len(data), 1, 28, 28) * .2\n",
    "                data += noise.to(device)\n",
    "\n",
    "            if denoiser:\n",
    "                data = denoiser(data)\n",
    "                \n",
    "            # standardization\n",
    "            data = (data - data.mean()) / data.std()\n",
    "    \n",
    "            target = target.to(device)\n",
    "            output = best_classifier(data)\n",
    "            accuracy.update((output, target))\n",
    "            precision.update((output, target))\n",
    "            recall.update((output, target))\n",
    "    \n",
    "    if not add_noise and not denoiser:\n",
    "        label = 'Clean accuracy'\n",
    "    elif add_noise and not denoiser:\n",
    "        label = 'Noisy accuracy'\n",
    "    elif add_noise and denoiser:\n",
    "        label = 'Denoised accuracy'\n",
    "    else:\n",
    "        label = 'Accuracy'\n",
    "\n",
    "    print(f'{label}: {accuracy.compute()}')\n",
    "#     print(f'Test precision: {precision.compute().mean()}')\n",
    "#     print(f'Test precision: {recall.compute().mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(best_classifier, MNIST_test_loader, accuracy, precision, recall, add_noise=False, denoiser=None)\n",
    "evaluate(best_classifier, MNIST_test_loader, accuracy, precision, recall, add_noise=True, denoiser=None)\n",
    "evaluate(best_classifier, MNIST_test_loader, accuracy, precision, recall, add_noise=True, denoiser=best_denoiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8fd258d9991467903c60070cf6af3d85aa3dae359f2e20f3ff90ca4877eb264"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
